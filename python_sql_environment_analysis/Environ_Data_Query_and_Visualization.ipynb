{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Data, Querying and Visualization of DB\n",
    "\n",
    "Note: This demo/portfolio utilizes notebooks as a way to better demostrate what I'm doing, and what each of my actions is doing. In reality, Notebooks would only be used for data visualization, whereas all Querying, Data Mutation, or Data Cleaning would not utilize this method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import panel as pn\n",
    "import hvplot.pandas\n",
    "import param\n",
    "\n",
    "import mysql.connector\n",
    "import mysql.connector.errorcode as errorcode\n",
    "from typing import Dict, List, Union\n",
    "from mysql.connector.types import RowType, RowItemType\n",
    "\n",
    "# Database configuration\n",
    "from DB_Constants import USR_CONFIG, DATABASE_NAMES, TABLE_NAMES, ENVIRON_TABLE_LOCATION_MAPPING, TABLE_TEMPLATES\n",
    "\n",
    "pn.extension(comms='ipywidgets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init and Maintain Connection \n",
    "class SqlConnection(param.Parameterized):\n",
    "    \n",
    "    def __init__(self, user_config):\n",
    "        try: \n",
    "            self.cnx = mysql.connector.connect(**user_config)\n",
    "            self.cursor = self.cnx.cursor()\n",
    "        except mysql.connector.Error as err:\n",
    "            print(f\"Error: {err}\")\n",
    "            self.Error= err\n",
    "        self.Error = None\n",
    "        \n",
    "    def close(self):\n",
    "        self.cursor.close()\n",
    "        self.cnx.close()\n",
    "        \n",
    "    def execute_query(self, query: str) -> bool:\n",
    "        \"\"\"executes a query on MySQL DB. \n",
    "\n",
    "        Args:\n",
    "            query (str): an string literal of the SQL command\n",
    "\n",
    "        Returns:\n",
    "            bool: True if query suceeded, False if it failed. \n",
    "        \"\"\"\n",
    "        try: \n",
    "            self.cursor.execute(query)\n",
    "        except mysql.connector.Error as err:\n",
    "            self.error = err\n",
    "            if err.errno == errorcode.ER_ACCESS_DENIED_ERROR:\n",
    "                print(\"SqlConnection.execute_query: Access denied. Check your username or password.\")\n",
    "                return False\n",
    "            elif err.errno == errorcode.ER_BAD_DB_ERROR:\n",
    "                print(\"SqlConnection.execute_query: Database does not exist.\")\n",
    "                return False\n",
    "            else:\n",
    "                print(f\"SqlConnection.execute_query: {err}\")\n",
    "                return False\n",
    "        return True \n",
    "    \n",
    "    def get_all_query_results(self) -> List[Union[RowType, Dict[str, RowItemType]]]: \n",
    "        return self.cursor.fetchall()\n",
    "    \n",
    "    def set_db(self, db_name) -> bool:\n",
    "        return self.execute_query(f\"USE {db_name};\")\n",
    "\n",
    "    def get_last_error(self) -> mysql.connector.Error:\n",
    "        return self.error        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(db_connection, table_name, table_schema):\n",
    "    print(f\"Creating table {table_name}: \", end='')\n",
    "    print(table_schema.format(tb_name=table_name))\n",
    "    db_connection.execute_query(table_schema.format(tb_name=table_name))\n",
    "    print(\"OK\")\n",
    "\n",
    "\n",
    "def create_database(db_connection, db_name):\n",
    "    try:\n",
    "        print(f\"Attempting to create DB named {db_name}\")\n",
    "        db_connection.cursor.execute(f\"CREATE DATABASE {db_name} DEFAULT CHARACTER SET 'utf8mb4'\")\n",
    "        print(f\"Created DB named {db_name}\")\n",
    "    except mysql.connector.Error as err:\n",
    "        if err.errno == errorcode.ER_DB_CREATE_EXISTS:\n",
    "            print(f\"Database {db_name} already exists.\")\n",
    "        else:\n",
    "            print(f\"Failed creating database: {err}\")\n",
    "            exit(1)\n",
    "\n",
    "\n",
    "def create_environ_db(db_connection):\n",
    "    db_create_query = f\"SELECT SCHEMA_NAME FROM INFORMATION_SCHEMA.SCHEMATA;\"\n",
    "    \n",
    "    try:\n",
    "        print(\"Attempting to create new DB in MySQL\") \n",
    "        db_connection.execute_query(db_create_query)\n",
    "        results = db_connection.get_all_query_results()\n",
    "        if DATABASE_NAMES['environ'] not in results:\n",
    "            create_database(db_connection, db_name=DATABASE_NAMES['environ'])\n",
    "        print(\"Attempt to create new DB in MySQL suceeded\")\n",
    "    except mysql.connector.Error as err: \n",
    "        print(err)\n",
    "\n",
    "    db_connection.set_db(DATABASE_NAMES['environ'])\n",
    "\n",
    "    for t_name, t_schema in TABLE_TEMPLATES.items():\n",
    "        create_table(db_connection, table_name=t_name, table_schema=t_schema)\n",
    "\n",
    "    print(f\"Database {DATABASE_NAMES['environ']} is ready!\")\n",
    "\n",
    "\n",
    "def verify_environ_db_tables(db_connection):\n",
    "    # MySQL connection configuration\n",
    "    try:\n",
    "        # List all tables\n",
    "        db_connection.execute_query(\"SHOW TABLES;\")\n",
    "        table_names = db_connection.get_all_query_results()\n",
    "        print(f\"\\nTables in `{DATABASE_NAMES['environ']}`:\")\n",
    "        for name in table_names:\n",
    "            print(f\"Table Name: {name}\")\n",
    "\n",
    "        # Verify structure of the specific table\n",
    "        print(f\"\\nStructure of `{TABLE_NAMES[0]}`:\")\n",
    "        db_connection.execute_query(f\"DESCRIBE `{TABLE_NAMES[0]}`;\")\n",
    "        rows = db_connection.get_all_query_results\n",
    "        for row in rows:\n",
    "            print(row)\n",
    "\n",
    "    except mysql.connector.Error as err:\n",
    "        if err.errno == errorcode.ER_ACCESS_DENIED_ERROR:\n",
    "            print(\"Access denied. Check your username or password.\")\n",
    "        elif err.errno == errorcode.ER_BAD_DB_ERROR:\n",
    "            print(\"Database does not exist.\")\n",
    "        else:\n",
    "            print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alter_table_with_location_id(db_connection):\n",
    "    # Alter the table to add a location_id column\n",
    "    alter_query = f\"\"\"\n",
    "        ALTER TABLE {TABLE_NAMES[0]}\n",
    "        ADD COLUMN location_id VARCHAR(50) AFTER dew_point_F;\n",
    "        \"\"\"\n",
    "\n",
    "    find_all_column_names_query = f\"\"\"\n",
    "        SELECT column_name FROM information_schema.columns\n",
    "        WHERE table_schema = '{DATABASE_NAMES['environ']}'\n",
    "        AND table_name = '{TABLE_NAMES[0]}';\n",
    "    \"\"\"\n",
    "    db_connection.execute_query(find_all_column_names_query)\n",
    "    col_names = db_connection.get_all_query_results()\n",
    "    location_col_added = False\n",
    "\n",
    "    for (name) in col_names:\n",
    "        if \"location_id\" in name:\n",
    "            location_col_added = True\n",
    "\n",
    "    if location_col_added == False:\n",
    "        db_connection.execute_query(alter_query)\n",
    "        print(\"Table altered successfully to include 'location_id' column.\")\n",
    "    else:\n",
    "        print(\"Table already altered to include 'location_id' column.\")\n",
    "\n",
    "\n",
    "def extract_location_id_from_filename(filename):\n",
    "    # Extract location ID from the filename (assuming it's a numeric fragment)\n",
    "    for i, location_id in enumerate(ENVIRON_TABLE_LOCATION_MAPPING):\n",
    "        if location_id in filename:\n",
    "            return location_id\n",
    "    return None  # Return None if no match is found\n",
    "\n",
    "\n",
    "def load_csv_to_mysql(db_connection, directory):\n",
    "    # Loop through all CSV files in the given directory\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(directory, file_name)\n",
    "\n",
    "            # Read the CSV file into a Pandas DataFrame\n",
    "            print(f\"Reading {file_name}: To add to MySQL DB\")\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # Extract location ID from the filename\n",
    "            location_id = extract_location_id_from_filename(file_name)\n",
    "            if location_id is None:\n",
    "                print(f\"Skipping {file_name}: No matching location ID found.\")\n",
    "                continue\n",
    "\n",
    "            # Insert data into the MySQL table\n",
    "            for _, row in df.iterrows():\n",
    "                insert_query = f\"\"\"\n",
    "                    INSERT INTO `{TABLE_NAMES[0]}` (entry_no, entry_datetime, temp_F, rh_percent, dew_point_F, location_id)\n",
    "                    VALUES (%s, %s, %s, %s, %s, %s)\n",
    "                    \"\"\"\n",
    "                # ['#', 'Date-Time (CDT)', 'Temperature (°F) ', 'RH (%) ', 'Dew Point (°F) '] \"%Y-%m-%d %H:%M:%S\"\n",
    "                # Parse and format the date-time field\n",
    "                formatted_date = datetime.datetime.strptime(\n",
    "                    row['Date-Time (CDT)'], \"%m/%d/%Y %H:%M:%S\")\n",
    "\n",
    "                # Prepare the data tuple\n",
    "                data = (\n",
    "                    row['#'],                                       # Order of entry into the orginal .csv file\n",
    "                    formatted_date.strftime('%Y-%m-%d %H:%M:%S'),   # Ensure correct format for MySQL DATETIME\n",
    "                    row['Temperature (°F) '],                       # Temperature\n",
    "                    row['RH (%) '],                                 # Relative Humidity\n",
    "                    row['Dew Point (°F) '],                         # Dew Point\n",
    "                    location_id                                     # Location ID\n",
    "                )\n",
    "                db_connection.cursor.execute(insert_query, data)\n",
    "\n",
    "            # Commit the transaction\n",
    "            db_connection.cnx.commit()\n",
    "            print(f\"Data from {file_name} loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sql_connection = SqlConnection(USR_CONFIG)\n",
    "\n",
    "    create_environ_db(sql_connection)\n",
    "    #verify_environ_db_tables(sql_connection)\n",
    "    \n",
    "    sql_connection.set_db(DATABASE_NAMES['environ'])\n",
    "\n",
    "    alter_table_with_location_id(db_connection=sql_connection)\n",
    "\n",
    "    # Specify the directory containing the CSV files\n",
    "    DIRECTORY_PATH = 'c:\\\\repos\\\\CSV_Visualizer\\\\data'  # Update to your directory\n",
    "    load_csv_to_mysql(db_connection=sql_connection, directory=DIRECTORY_PATH)\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error: {err}\")\n",
    "finally:\n",
    "    sql_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sqlalchemy\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import holoviews as hv\n",
    "\n",
    "con_string = f\"mysql+pymysql://{USR_CONFIG['user']}:{USR_CONFIG['password']}@{USR_CONFIG['host']}/{DATABASE_NAMES['environ']}\"\n",
    "sqlalchemy_engine = create_engine(con_string)\n",
    "\n",
    "sql_connection = SqlConnection(USR_CONFIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def query_mysql(db, sqlengine, query, params=None):\n",
    "    \"\"\"Execute a SQL query and return the result as a Pandas DataFrame.\"\"\"\n",
    "    try:\n",
    "        db.cursor.execute(f\"USE {DATABASE_NAMES['environ']};\")\n",
    "        df = pd.read_sql(query, sqlengine, params=params)\n",
    "        return df\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Error: {err}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame on error\n",
    "      \n",
    "\n",
    "# Interactive widgets\n",
    "start_date_widget = pn.widgets.DatePicker(\n",
    "    name=\"Start Date Picker\", value=datetime.datetime(2024, 5, 2))\n",
    "end_date_widget = pn.widgets.DatePicker(\n",
    "    name=\"End Date Picker\", value=datetime.datetime(2024, 7, 26))\n",
    "\n",
    "location_key_list = list(ENVIRON_TABLE_LOCATION_MAPPING.keys())\n",
    "location_select_widget = pn.widgets.MultiChoice(\n",
    "    name=\"Location MultiChoice\", value=[location_key_list[0]], options=location_key_list)\n",
    "\n",
    "\n",
    "def location_select_handler(location_select, query, params):\n",
    "    if location_select:  # Check if the list is not empty\n",
    "        placeholders = \", \".join([\"%s\"] * len(location_select))\n",
    "        query += f\" AND location_id IN ({placeholders})\"\n",
    "        params += tuple(location_select)\n",
    "    return (location_select, query, params)\n",
    "        \n",
    "# Graphs\n",
    "def time_series_plot(start_date, end_date, location_select):\n",
    "    \"\"\"Fetch data for the time-series plot and generate the plot.\"\"\"\n",
    "    query = f\"\"\"\n",
    "        SELECT entry_datetime, temp_F, location_id\n",
    "        FROM {TABLE_NAMES[0]}\n",
    "        WHERE entry_datetime BETWEEN %s AND %s\n",
    "    \"\"\"\n",
    "    params = (start_date, end_date)\n",
    "    _, query, params = location_select_handler(location_select, query, params)\n",
    "\n",
    "    df = query_mysql(sql_connection, sqlalchemy_engine, query, params)\n",
    "    \n",
    "    if df.empty:\n",
    "        return \"No data available for the selected filters.\"\n",
    "    \n",
    "    return df.hvplot.line(\n",
    "        x=\"entry_datetime\", \n",
    "        y=\"temp_F\", \n",
    "        by=\"location_id\", \n",
    "        title=\"Temperature Over Time\", \n",
    "        ylabel=\"Temperature (°F)\", \n",
    "        xlabel=\"Date\",\n",
    "        legend=\"top_right\"\n",
    "    )\n",
    "\n",
    "\n",
    "def scatter_plot(start_date, end_date, location_select):\n",
    "    \"\"\"Fetch data for the scatter plot and generate the plot.\"\"\"\n",
    "    query = f\"\"\"\n",
    "        SELECT temp_F, rh_percent, location_id\n",
    "        FROM {TABLE_NAMES[0]}\n",
    "        WHERE entry_datetime BETWEEN %s AND %s\n",
    "    \"\"\"\n",
    "    params = (start_date, end_date)\n",
    "    _, query, params = location_select_handler(location_select, query, params)\n",
    "\n",
    "    df = query_mysql(sql_connection, sqlalchemy_engine, query, params)\n",
    "    \n",
    "    if df.empty:\n",
    "        return \"No data available for the selected filters.\"\n",
    "    \n",
    "    return df.hvplot.scatter(\n",
    "        x=\"temp_F\", \n",
    "        y=\"rh_percent\", \n",
    "        color=\"location_id\", \n",
    "        title=\"Temperature vs Relative Humidity\",\n",
    "        xlabel=\"Temperature (°F)\", \n",
    "        ylabel=\"RH (%)\", \n",
    "        alpha=0.2, \n",
    "        legend=\"top_right\"\n",
    "    )\n",
    "\n",
    "\n",
    "def box_plot(start_date, end_date, location_select):\n",
    "    \"\"\"Fetch data for the box plot and generate the plot.\"\"\"\n",
    "    query = f\"\"\"\n",
    "        SELECT temp_F, location_id\n",
    "        FROM {TABLE_NAMES[0]}\n",
    "        WHERE entry_datetime BETWEEN %s AND %s\n",
    "    \"\"\"\n",
    "    params = (start_date, end_date)\n",
    "    _, query, params = location_select_handler(location_select, query, params)\n",
    "\n",
    "    df = query_mysql(sql_connection, sqlalchemy_engine, query, params)\n",
    "    \n",
    "    if df.empty:\n",
    "        return \"No data available for the selected filters.\"\n",
    "    \n",
    "    return df.hvplot.box(\n",
    "        y=\"temp_F\", \n",
    "        by=\"location_id\", \n",
    "        color=\"location_id\",\n",
    "        title=\"Temperature Distribution by Location\", \n",
    "        ylabel=\"Temperature (°F)\", \n",
    "        xlabel=\"Location Where Data was Collected\", \n",
    "        legend=\"top_right\"\n",
    "    )\n",
    "\n",
    "\n",
    "main_block = pn.Column(pn.Row(start_date_widget, end_date_widget, location_select_widget),\n",
    "                              pn.bind(time_series_plot, start_date_widget,\n",
    "                                      end_date_widget, location_select_widget),\n",
    "                              pn.bind(scatter_plot, start_date_widget,\n",
    "                                      end_date_widget, location_select_widget),\n",
    "                              pn.bind(box_plot, start_date_widget, \n",
    "                                      end_date_widget, location_select_widget)\n",
    ")\n",
    "\n",
    "# Layout the dashboard\n",
    "dashboard = pn.Column(\n",
    "    \n",
    "    \"## Environmental Data Dashboard\",\n",
    "    main_block,\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_all_column_names_query = f\"\"\"\n",
    "    SELECT column_name FROM information_schema.columns\n",
    "    WHERE table_schema = '{DATABASE_NAMES['environ']}'\n",
    "    AND table_name = '{TABLE_NAMES[0]}';\n",
    "\"\"\"\n",
    "\n",
    "cols = query_mysql(sql_connection, sqlalchemy_engine, find_all_column_names_query)\n",
    "cols.drop(index=0, axis=1, inplace=True)\n",
    "\n",
    "cols_list = cols.iloc[:,0].tolist()\n",
    "\n",
    "x_widget = pn.widgets.Select(name='X-Axis', options=cols_list)\n",
    "y_widget = pn.widgets.Select(name='Y-Axis', options=cols_list)\n",
    "\n",
    "wig = pn.Column(x_widget, y_widget, location_select_widget)\n",
    "wig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming TABLE_NAMES and DATABASE_NAMES are predefined\n",
    "def correlation_analysis(x_widget_value, y_widget_value, _locat):\n",
    "    print(\"Selected Locations:\", _locat)\n",
    "    print(\"Type of location input:\", type(_locat))\n",
    "    \n",
    "    # Validate inputs\n",
    "    if not x_widget_value or not y_widget_value:\n",
    "        raise ValueError(\"Both x_widget_value and y_widget_value must be provided.\")\n",
    "    if not isinstance(_locat, list):\n",
    "        raise ValueError(\"`_locat` must be a list of location IDs.\")\n",
    "    \n",
    "    # Construct query with column names dynamically\n",
    "    correlation_query = f\"\"\"\n",
    "        SELECT `{x_widget_value}`, `{y_widget_value}` FROM {TABLE_NAMES[0]}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add location filtering\n",
    "    params = []\n",
    "    if _locat:  # If specific locations are provided\n",
    "        location_conditions = \" OR \".join([f\"location_id = %s\" for _ in _locat])\n",
    "        query = f\"SELECT `{x_widget_value}`, `{y_widget_value}` FROM {TABLE_NAMES[0]} WHERE {location_conditions}\"\n",
    "        params.extend(_locat)\n",
    "    else:  # No locations provided, fetch all rows\n",
    "        print(\"No locations provided, fetching data for all locations.\")\n",
    "    \n",
    "    print(\"Constructed Query:\", correlation_query)\n",
    "    print(\"Query Parameters:\", param)\n",
    "    \n",
    "    try:\n",
    "        # Execute query and load data into a DataFrame\n",
    "        sql_connection.cursor.execute(f\"USE {DATABASE_NAMES['environ']};\")\n",
    "        df = pd.read_sql(correlation_query.format(param), sqlalchemy_engine)\n",
    "        \n",
    "        if df.empty:\n",
    "            return \"No data available for the selected filters.\"\n",
    "        \n",
    "        # Create hvplot KDE visualization\n",
    "        return df.hvplot.scatter(\n",
    "            x=x_widget_value,\n",
    "            y=y_widget_value,\n",
    "            alpha=0.8,\n",
    "            xlabel=x_widget_value,\n",
    "            ylabel=y_widget_value,\n",
    "            title=f\"Correlation Analysis: {x_widget_value} vs {y_widget_value}\"\n",
    "        )\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error executing query: {e}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame on error\n",
    "\n",
    "    \n",
    "display_pane1 = pn.Column(x_widget, y_widget, location_select_widget, pn.bind(correlation_analysis, x_widget,\n",
    "                                      y_widget, location_select_widget))\n",
    "#display_pane = pn.Column(widgets, correlation_analysis)\n",
    "display_pane1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Database connection configuration\n",
    "config = {\n",
    "    'user': 'your_username',\n",
    "    'password': 'your_password',\n",
    "    'host': 'localhost',\n",
    "    'database': 'EnvironmentDataDB',\n",
    "}\n",
    "\n",
    "def fetch_data():\n",
    "    \"\"\"Fetch relevant data from the MySQL database.\"\"\"\n",
    "    try:\n",
    "        # Connect to the database\n",
    "        cnx = mysql.connector.connect(**config)\n",
    "        \n",
    "        # SQL query to fetch the data\n",
    "        query = \"\"\"\n",
    "        SELECT entry_datetime, temp_F, dew_point_F, rh_percent, location_id\n",
    "        FROM environ_data_table\n",
    "        WHERE rh_percent IS NOT NULL;  -- Ensure RH is available\n",
    "        \"\"\"\n",
    "        \n",
    "        # Fetch data into a Pandas DataFrame\n",
    "        df = pd.read_sql(query, cnx)\n",
    "        \n",
    "        # Close the connection\n",
    "        cnx.close()\n",
    "        \n",
    "        return df\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Error: {err}\")\n",
    "        return pd.DataFrame()  # Return empty DataFrame on error\n",
    "\n",
    "def bucket_and_plot(df):\n",
    "    \"\"\"Bucket relative humidity and plot distribution.\"\"\"\n",
    "    # Define RH buckets\n",
    "    bins = [0, 20, 40, 60, 80, 100]\n",
    "    labels = [\"0-20%\", \"21-40%\", \"41-60%\", \"61-80%\", \"81-100%\"]\n",
    "\n",
    "    # Assign RH values to buckets\n",
    "    df[\"rh_bucket\"] = pd.cut(df[\"rh_percent\"], bins=bins, labels=labels, right=True)\n",
    "\n",
    "    # Count occurrences in each bucket\n",
    "    bucket_counts = df[\"rh_bucket\"].value_counts().sort_index()\n",
    "\n",
    "    # Plot the distribution\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    bucket_counts.plot(kind=\"bar\", color=\"skyblue\")\n",
    "    plt.title(\"Relative Humidity Distribution\")\n",
    "    plt.xlabel(\"Relative Humidity Buckets\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def bucket_and_plot_by_location(df):\n",
    "    \"\"\"Bucket relative humidity and plot distribution by location.\"\"\"\n",
    "    # Define RH buckets\n",
    "    bins = [0, 20, 40, 60, 80, 100]\n",
    "    labels = [\"0-20%\", \"21-40%\", \"41-60%\", \"61-80%\", \"81-100%\"]\n",
    "\n",
    "    # Assign RH values to buckets\n",
    "    df[\"rh_bucket\"] = pd.cut(df[\"rh_percent\"], bins=bins, labels=labels, right=True)\n",
    "\n",
    "    # Group by location and bucket\n",
    "    grouped = df.groupby([\"location_id\", \"rh_bucket\"]).size().unstack(fill_value=0)\n",
    "\n",
    "    # Plot for each location\n",
    "    grouped.plot(kind=\"bar\", figsize=(10, 6), stacked=True, colormap=\"viridis\")\n",
    "    plt.title(\"Relative Humidity Distribution by Location\")\n",
    "    plt.xlabel(\"Location ID\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend(title=\"RH Buckets\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Fetch data from MySQL\n",
    "    data = fetch_data()\n",
    "\n",
    "    if not data.empty:\n",
    "        # Plot overall distribution\n",
    "        bucket_and_plot(data)\n",
    "\n",
    "        # Plot distribution by location\n",
    "        bucket_and_plot_by_location(data)\n",
    "    else:\n",
    "        print(\"No data available to process.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
